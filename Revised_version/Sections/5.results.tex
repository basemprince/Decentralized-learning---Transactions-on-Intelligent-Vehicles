\section{Results}
% All this Sec.~will be 1/2 pages.


%The testing process began with a single worker (centralized \gls*{gan}) in order to determine the optimal layer architecture for the generator and discriminator. We initially conducted the testing using anomalous data, and then normal data was introduced later on.
We compared the performance of centralized \gls*{gan} (i.e., a single worker) with our decentralized approach. 
For evaluation, we trained 3 separate auto-regression models \gls*{trtr} for each data behaviour (normal, anomalous, mixed). Each \gls*{trtr} model is needed to calculate the corresponding \gls*{trts} for the \gls*{gan} getting tested. The auto-regression models are set-up to predict the last five time steps.
%
As shown in Tab.~\ref{tab:trtr-main}, the regression model has a higher R2 score when applied to the normal behaviour data-set. This suggests that the model is more accurate on normal data rather than anomalous or mixed ones. We use the \gls*{trtr} metric to verify the results when applied to synthetic data. In particular, we tested each \gls*{trtr} on 10 different synthetic data samples from each generator to calculate an average for the \gls*{trts} metric. Similarly, we trained an auto-regression model with synthetic data 10 different times to calculate an average for the \gls*{tstr} metric.

\input{Tables/trtr}


\subsection{Centralized GAN Results}

We tested the \gls*{gan} model initially using fixed sequence widths of 64, 128, and 256 seconds. The results show a sequence width of 64 seconds being the better performer if we used the fixed sequence strategy width. After applying the dynamic window strategy, both visual inspection and the \gls*{trts} / \gls*{tstr} (see Tab.~\ref{tab:dynamic-window}) showed an improvement. This confirms that the dynamic window in fact improves the capabilities of the generator in contrast to using a fixed sequence width.

\input{Tables/dynamic-window}
%
The normalization we used in previous tests employed the first technique mentioned in Sec.~\ref{sec:data-pre-process}, where each feature is normalized based on the known capabilities of that specific feature. We then further tested the second technique, where the normalization occurs based on the limits of the workers. The \gls*{trts} / \gls*{tstr} results in Tab.~\ref{tab:normalize-result} showed that using the worker limits yields a significant improvement. We adapted the second technique to all upcoming tests.
\input{Tables/normalize-result}


\subsection{Decentralized GAN Results}
%
We set-up the network with one server and four workers. Workers \#1 and \#2 had anomalous data, while workers \#3 and \#4 had normal data.
As shown in Fig.~\ref{fig:decentralized_results}, the output sequence generated by the most forgiving strategy only contain behaviour belonging to workers \#1 and \#2 (Anomalous), while the least forgiving strategy produces a mix of classes from both workers. This output shows both normal and anomalous behaviour, which looks similar to the mixed data behaviour shown in Fig.~\ref{fig:scania-data}. This can also be corroborated by examining the worker contribution count, which tracks the number of times each worker was selected for generator training (see Fig.~\ref{fig:work-cont-decentralized}. The most forgiving strategy exhibits a strong bias towards workers \#1 and \#2, while the least forgiving strategy exhibits a more balanced distribution. This explains the difference in output observed in the generated sequences.

\input{Tables/decentralized-tstr}

The behaviour of the most forgiving strategy can be understood as follows; in this approach, the generator is updated based on the worker with the highest loss on the fake data produced by the generator. This leads to the generator creating fake data that closely resembles the data of the selected worker. In subsequent iterations, it is expected that the previously selected worker will have a higher loss on the fake images, as the generator is more specialized to their data. On the other hand, the rest of the workers are likely to have a lower loss, insuring a much less likelihood of being selected. As the training process continues, the generator is expected to converge on a small subset of workers, effectively ignoring the data of other workers as the distribution of generated data is very different from their local data distribution. 

We also implemented and tested two different forms of weighting for the averaging technique (\gls*{f2a}), one that favoured the most forgiving worker and another that favoured the least forgiving worker. We used the Softmax function to determine the contribution of each worker to the overall average model. In the next iteration, all workers used the newly averaged discriminator model. However, there was a noticeable output degradation as suggested by the \gls*{trts} / \gls*{tstr} results and the output sequence shown in Fig.~\ref{fig:decentralized_results}.
%
\input{Figures/decentralized_results}
%
\input{Figures/worker-cont-decentralized}
%
%\input{Figures/pca-decentralized}



